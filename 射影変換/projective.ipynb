{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# ET-robot-contest Game Area Detection and find block color.\n",
    "# Copyright © 2022 naoki hunada. All rights reserved.\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawpoint(img, point_pos_list, color=(255, 255, 255), size=3):\n",
    "        for num,i in enumerate(point_pos_list):\n",
    "            cv2.circle(img, i, size, color, thickness=-1, lineType=cv2.LINE_AA, shift=0)\n",
    "            cv2.circle(img, i, size, (0, 0, 0), thickness=1, lineType=cv2.LINE_AA, shift=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 交点を求める(未使用)\n",
    "def find_intersection(line1_pos1, line1_pos2, line2_pos1, line_2_pos2):\n",
    "    x1, y1 = line1_pos1\n",
    "    x2, y2 = line1_pos2\n",
    "    x3, y3 = line2_pos1\n",
    "    x4, y4 = line_2_pos2\n",
    "\n",
    "    denom = ((y4 - y3) * (x2 - x1)) - ((x4 - x3) * (y2 - y1))\n",
    "    if denom == 0:\n",
    "        return None\n",
    "\n",
    "    numerator1 = ((x4 - x3) * (y1 - y3)) - ((y4 - y3) * (x1 - x3))\n",
    "    numerator2 = ((x2 - x1) * (y1 - y3)) - ((y2 - y1) * (x1 - x3))\n",
    "\n",
    "    a = numerator1 / denom\n",
    "    b = numerator2 / denom\n",
    "\n",
    "    if a > 0 and a < 1 and b > 0 and b < 1:\n",
    "        x = x1 + (a * (x2 - x1))\n",
    "        y = y1 + (a * (y2 - y1))\n",
    "        return (x, y)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 難所の中心座標から各点までの相対座標を求める(未使用)\n",
    "def point_scale(point, scale):\n",
    "    p = np.array(point)\n",
    "    COG = find_intersection(point[0], point[2], point[1], point[3])\n",
    "    print(COG)\n",
    "    relative_p = p - COG\n",
    "    ret = np.round(relative_p * scale + COG, 0)\n",
    "    ret = ret.astype(np.int64)\n",
    "    return ret.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### エリアの角のポイントからscale分の距離で射影変換する\n",
    "def area_perspective_transform(img, point, scale):\n",
    "    height, width, channels = img.shape[:3]\n",
    "    size = 300\n",
    "    b_size = 10\n",
    "    b_dist = -100\n",
    "\n",
    "    source_points1 = np.array([point[0], point[1], point[2], point[3]], dtype=np.float32)\n",
    "    target_points = np.array([[0, 0], [0, size], [size, size], [size, 0]], dtype=np.float32)\n",
    "\n",
    "    mat1 = cv2.getPerspectiveTransform(source_points1, target_points)\n",
    "    mat2 = cv2.getPerspectiveTransform(target_points, source_points1)\n",
    "    \n",
    "    #エリアの射影変換\n",
    "    diff = scale\n",
    "    area_point = np.array([[[0-diff, 0-diff], [size+diff, 0-diff], [size+diff, size+diff], [0-diff, size+diff]]], dtype='float32')\n",
    "    area_point = cv2.perspectiveTransform(area_point, mat2)\n",
    "    area_point = area_point[0]\n",
    "    source_points2 = np.array([area_point[0], area_point[1], area_point[2], area_point[3]], dtype=np.float32)\n",
    "    mat3 = cv2.getPerspectiveTransform(source_points2, target_points)\n",
    "    perspective_image1 = cv2.warpPerspective(img, mat3, (size, size))\n",
    "\n",
    "    #ボーナスブロックの射影変換\n",
    "    b_point = np.array([[[0-b_size+b_dist, 300-b_size], [0+b_size+b_dist, 300-b_size], [0+b_size+b_dist, 300+b_size], [0-b_size+b_dist, 300+b_size]]], dtype='float32')\n",
    "    b_point = cv2.perspectiveTransform(b_point, mat2)\n",
    "    area_point = area_point[0]\n",
    "    source_points3 = np.array([area_point[0], area_point[1], area_point[2], area_point[3]], dtype=np.float32)\n",
    "    mat4 = cv2.getPerspectiveTransform(source_points3, target_points)\n",
    "    perspective_image2 = cv2.warpPerspective(img, mat4, (b_size*2, b_size*2))\n",
    "\n",
    "    #p = np.array([[[-50, -50]]], dtype='float32')\n",
    "    #pointsOut = cv2.perspectiveTransform(p, mat2)\n",
    "    #print(pointsOut)\n",
    "\n",
    "    return perspective_image1, perspective_image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonus_block_perspective_transform(img, point, scale):\n",
    "    a = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"a.png\")\n",
    "#point = [[282, 195], [196, 71], [59, 104], [109, 261]]\n",
    "#drawpoint(img, point)\n",
    "#img = area_perspective_transform(img, point, 82)\n",
    "#plt.imshow(np.asarray(img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
