{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# ET-robot-contest Game Area Detection and find block color.\n",
    "# Copyright © 2022 naoki hunada. All rights reserved.\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import math\n",
    "import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 環境変数\n",
    "PROCESS_IMAGE_SIZE = [300, 320]\n",
    "IMAGE_MASK_MIN_THRESHOLD = [0,51,70] #HSV\n",
    "IMAGE_MASK_MAX_THRESHOLD = [255,255,255] #HSV\n",
    "LINE_COLOR_DETECTION_FINENESS = 30\n",
    "LINE_COLOR_DETECTION_SCORE_THRESHOLD = 550\n",
    "LINE_COLOR_DETECTION_MAX_THRESHOLD = [255,255,45] #HSV\n",
    "LINE_DETECTION_ROTATE_RANGE = 1.7\n",
    "POINT_DETECTION_MIN_AREA_THRESHOLD = 30\n",
    "POINT_DETECTION_MAX_AREA_THRESHOLD = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 座標から0~360度の範囲で返す 引数 pos = [x,y]\n",
    "def pos2deg(pos):\n",
    "    posh = [i + 0.001 for i in pos]\n",
    "    deg = math.degrees(math.atan(posh[1]/posh[0]))\n",
    "    if(posh[0] >= 0 and posh[1] < 0):\n",
    "        deg += 360\n",
    "    elif(posh[0] < 0 and posh[1] >= 0):\n",
    "        deg += 180\n",
    "    elif(posh[0] < 0 and posh[1] < 0):\n",
    "        deg += 180\n",
    "    return deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ラインの中心座標を求める\n",
    "def line_COG(line_pos_list):\n",
    "    lpl = deepcopy(line_pos_list)\n",
    "    line_COG = []\n",
    "    line_pos_COG = []\n",
    "    # 各座標から重心を求める\n",
    "    for i in lpl:\n",
    "        x = 0\n",
    "        y = 0\n",
    "        for j in i:\n",
    "            x += j[0]\n",
    "            y += j[1]\n",
    "        x = x / len(i)\n",
    "        y = y / len(i)\n",
    "        # 重心からの距離を求める\n",
    "        distance = []\n",
    "        for num, j in enumerate(i):\n",
    "            distance.append([num, math.sqrt((j[0] - x)**2 + (j[1] - y)**2)])\n",
    "        distance = sorted(distance, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        pos = np.round((i[distance[0][0]] + i[distance[1][0]]) / 2)\n",
    "        line_COG.append(pos.astype(np.int64))\n",
    "        line_pos_COG.append([i[distance[0][0]].tolist(), i[distance[1][0]].tolist()])\n",
    "        #line_COG.append([i[distance[0][0]], i[distance[1][0]]])\n",
    "\n",
    "    return line_COG, line_pos_COG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 推測した直線を描画する\n",
    "def drawline(img, line_pos_list, color=(0, 0, 255), size= 1):\n",
    "    for i in line_pos_list:\n",
    "        for j in i:\n",
    "            for k in i:\n",
    "                cv2.line(img, (j[0], j[1]), (k[0], k[1]), color, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 指定座標にポイントを描画する\n",
    "def drawpoint(img, point_pos_list, color=(255, 255, 255)):\n",
    "    for num,i in enumerate(point_pos_list):\n",
    "        cv2.circle(img, i, 3, color, thickness=-1, lineType=cv2.LINE_AA, shift=0)\n",
    "        cv2.circle(img, i, 3, (0, 0, 0), thickness=1, lineType=cv2.LINE_AA, shift=0)\n",
    "    #cv2.putText(point_pos_list, str(num), i, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pos1 から pos2までの直線pxのlistを返す nは分割数\n",
    "def create_line_point(pos1, pos2, n):\n",
    "  npos1 = np.array(pos1)\n",
    "  npos2 = np.array(pos2)\n",
    "  \n",
    "  dpos = (npos2 - npos1) / (n + 1)\n",
    "\n",
    "  pos = npos1\n",
    "  li = []\n",
    "  for i in range(n):\n",
    "    pos = pos + dpos\n",
    "    li.append(pos.tolist())\n",
    "  li = np.unique(np.round(li, 0), axis=0)\n",
    "  li = li.astype(np.int64)\n",
    "  return li.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2値化imgからpos_listの座標の色を取得した平均を返す(HSV)\n",
    "def get_avg_color(bit_img, pos_list):\n",
    "  bias_list = []\n",
    "  bias = 0\n",
    "  \n",
    "  for i in pos_list:\n",
    "    if(bit_img[i[1], i[0]] == 255):\n",
    "      if(bias >= 0):\n",
    "        bias += 1\n",
    "      else:\n",
    "        bias_list.append(bias)\n",
    "        bias = 1\n",
    "    else:\n",
    "      if(bias <= 0):\n",
    "        bias -= 1\n",
    "      else:\n",
    "        bias_list.append(bias)\n",
    "        bias = -1\n",
    "  bias_list.append(bias)\n",
    "  return np.sum(bias_list * np.abs(bias_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2値化img画像とline_list間の適合を調べる(find_line関数で主に使用)\n",
    "def check_color(bit_img, line):\n",
    "  li_COG, li_pos_COG = line_COG([line])\n",
    "  pos_list = create_line_point(li_pos_COG[0][0], li_pos_COG[0][1], LINE_COLOR_DETECTION_FINENESS) # |n 調整箇所|\n",
    "  ret = get_avg_color(bit_img, pos_list)\n",
    "  return ret >= LINE_COLOR_DETECTION_SCORE_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 検知した直線のポイントにlimit数分の制限にして返す(削除の順番はtarget_point座標から一番遠い場所) (find_line関数で主に使用)\n",
    "def limit_point(target_point, line, li_pos, limit):\n",
    "    target_index = li_pos.index(target_point)\n",
    "    ret_line = []\n",
    "    ret_li_pos = []\n",
    "    if(len(line) > limit):\n",
    "        pca = PCA(n_components=1)\n",
    "        pca.fit(li_pos)\n",
    "        pca_line = pca.transform(li_pos)\n",
    "        pca_line = abs(pca_line - pca_line[target_index])\n",
    "        pca_line = [[i, a[0]] for i,a in enumerate(pca_line)]\n",
    "        pca_line = sorted(pca_line, reverse=False, key = lambda x: x[1])\n",
    "        for i,a in enumerate(pca_line):\n",
    "            ret_line.append(line[a[0]])\n",
    "            ret_li_pos.append(li_pos[a[0]])\n",
    "            if(i == limit - 1):\n",
    "                break\n",
    "    else:\n",
    "        ret_line = line\n",
    "        ret_li_pos = li_pos\n",
    "    return ret_line, ret_li_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ポイント[x, y]の配列からpoint以上の数からなる直線を探す {引数} point:[[座標]], min_point:最小ポイント数 bit_img:２値化画像\n",
    "def find_line(point, count, tolerance, bit_img):\n",
    "    c_point = []\n",
    "    point2 = [[i, a] for i, a in enumerate(point)]\n",
    "    #print(point2)\n",
    "    used_point = [[i] for i in range(len(point2))]\n",
    "    line_list = []\n",
    "\n",
    "    for i, x in enumerate(point2): #各ポイントからポイントへの角度を割り出す\n",
    "        comp = deepcopy(point2)\n",
    "        comp = [[j[0], j[1]] for j in comp if not(j[0] in used_point[i])] #used_pointのポイントを除外\n",
    "        relative = np.array([a[1] - x[1] for a in comp])\n",
    "\n",
    "        #相対角度の計算\n",
    "        deg = np.array([[[comp[j][0], pos2deg([a[0], a[1]])] for j, a in enumerate(relative)]])\n",
    "        deg = deg[0][np.argsort(deg[0][:, 1])]\n",
    "        diff = np.array([abs(deg[i][1] - deg[i+1][1]) for i in range(len(deg)-1)]) #ソートした相対角度を角度の差分値でとる\n",
    "        #直線であるポイントを探索\n",
    "        match_count = 0 #直線上のポイント数\n",
    "        line = [x[0]]\n",
    "        for a, val in enumerate(diff):\n",
    "            if(val <= tolerance):# tolerance度以内であれば直線と判断\n",
    "                if(not(deg[a][0] in line)):\n",
    "                   line.append(int(deg[a][0]))\n",
    "                if(not(deg[a + 1][0] in line)):\n",
    "                   line.append(int(deg[a + 1][0]))\n",
    "            else:# 満たしてなければ引数条件で直線リストに格納\n",
    "                li_pos = [point2[i][1] for i in line]\n",
    "                line, li_pos = limit_point(x[1], line, li_pos, count)\n",
    "                if(len(line) >= count and check_color(bit_img, li_pos)): # |色 調整箇所|\n",
    "                    for b in line:\n",
    "                        for c in line:\n",
    "                            if(not(c in used_point[b])):\n",
    "                                used_point[b].append(c)\n",
    "                    line_list.append(line)\n",
    "                line = [x[0]]\n",
    "        \n",
    "        li_pos = [point2[i][1] for i in line]\n",
    "        line, li_pos = limit_point(x[1], line, li_pos, count)\n",
    "        if(len(line) >= count and check_color(bit_img, li_pos)):# 終了時の格納 |色 調整箇所|\n",
    "            for b in line:\n",
    "                for c in line:\n",
    "                    if(not(c in used_point[b])):\n",
    "                        used_point[b].append(c)\n",
    "            line_list.append(line)\n",
    "    #推測したポイント番号を座標に変換\n",
    "    line_pos_list = []\n",
    "    for i in line_list:\n",
    "        line_pos = []\n",
    "        for j in i:\n",
    "            line_pos.append(point2[j][1])\n",
    "        line_pos_list.append(line_pos)\n",
    "    return line_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 画像処理 閾値マスク (hsv)\n",
    "def img_mask(img, min, max):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv_min = np.array(min)\n",
    "    hsv_max = np.array(max) # |調整箇所|\n",
    "    mask = cv2.inRange(hsv, hsv_min, hsv_max)\n",
    "    masked_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    return masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(img):\n",
    "    size = PROCESS_IMAGE_SIZE# |調整箇所|\n",
    "    \n",
    "    image = img\n",
    "    image = cv2.resize(image, dsize=size)\n",
    "    outputImg = deepcopy(image)\n",
    "    rawImg = deepcopy(image)\n",
    "    height, width, channels = image.shape[:3]\n",
    "    \n",
    "    # 画像処理\n",
    "    #サークル間の黒ライン　と カラーサークル\n",
    "    mask_line = img_mask(image, [0, 0, 0], LINE_COLOR_DETECTION_MAX_THRESHOLD)\n",
    "    mask_line = cv2.cvtColor(mask_line, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask_line = cv2.threshold(mask_line, 1, 255, cv2.THRESH_BINARY)\n",
    "    #カラーサークル\n",
    "    mask_circle = img_mask(image, IMAGE_MASK_MIN_THRESHOLD, IMAGE_MASK_MAX_THRESHOLD)\n",
    "    mask_circle = cv2.cvtColor(mask_circle, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask_circle = cv2.threshold(mask_circle, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    #(サークル間の黒ライン　と カラーサークル) モルフォロジー処理、合成\n",
    "    bit_area = mask_circle | mask_line\n",
    "    kernel = np.ones((4,4),np.uint8)\n",
    "    bit_area = cv2.dilate(bit_area, kernel, iterations = 1)\n",
    "    #(カラーサークル) エッジ、モルフォロジー処理\n",
    "    mask_circle = cv2.Canny(mask_circle, 50, 100)\n",
    "    kernel = np.ones((2,2),np.uint8)\n",
    "    mask_circle = cv2.dilate(mask_circle, kernel, iterations = 1)\n",
    "\n",
    "    #輪郭取得    \n",
    "    contours, hierarchy= cv2.findContours(mask_circle, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    pointer = [i for i in range(len(contours))] #排除用\n",
    "    len(contours) \n",
    "    \n",
    "    # 輪郭の面積を計算する。\n",
    "    for i in pointer:\n",
    "        cnt = contours[i]\n",
    "        area = cv2.contourArea(cnt)\n",
    "        #print(f\"contour: {i}, area: {area}\")\n",
    "        if(not(POINT_DETECTION_MIN_AREA_THRESHOLD < area and area < POINT_DETECTION_MAX_AREA_THRESHOLD)):# |領域 調整箇所|\n",
    "            pointer[i] = -1\n",
    "    \n",
    "    pointer = [i for i in pointer if i != -1] #除外された輪郭を削除\n",
    "    \n",
    "    COG = [] #重心の配列\n",
    "    \n",
    "    for i in pointer:\n",
    "        try:\n",
    "            cnt = contours[i]\n",
    "            # 輪郭のモーメントを計算する。\n",
    "            M = cv2.moments(cnt)\n",
    "            # モーメントから重心を計算する。\n",
    "            cx = int(round(M[\"m10\"] / M[\"m00\"],0))\n",
    "            cy = int(round(M[\"m01\"] / M[\"m00\"],0))\n",
    "            COG.append([cx, cy])\n",
    "        except:\n",
    "            pointer[i] = -1\n",
    "        #print(f\"contour: {i}, centroid: ({cx:.2f}, {cy:.2f})\")\n",
    "    \n",
    "    pointer = [i for i in pointer if i != -1] #除外された輪郭を削除\n",
    "    \n",
    "\n",
    "    if(len(COG) < 3):\n",
    "        return outputImg\n",
    "    #COG.append([122, 305])\n",
    "    #絞りだしたポイントから4つの重なる直線を調べる\n",
    "    COG = np.array(COG)\n",
    "    li_list = find_line(COG, 4, LINE_DETECTION_ROTATE_RANGE, bit_area)# |直線 調整箇所|\n",
    "    li_COG, li_pos_COG = line_COG(li_list)\n",
    "    drawline(outputImg, li_list)\n",
    "    #推測した直線の端のポイントを対象として再度ラインを見つける\n",
    "    point = np.array([i[0] for i in li_pos_COG] + [i[1] for i in li_pos_COG])\n",
    "    point = np.unique(point, axis=0)\n",
    "    \n",
    "    li_list = find_line(point, 4, LINE_DETECTION_ROTATE_RANGE, bit_area)# |直線 調整箇所|\n",
    "    li_COG, li_pos_COG = line_COG(li_list)\n",
    "    \n",
    "    #推測したラインの端のポイントから引いているラインの数を数えて、2未満のものは削除\n",
    "    point = np.array([i[0] for i in li_pos_COG] + [i[1] for i in li_pos_COG])\n",
    "    point, count = np.unique(point, return_counts=True, axis=0)\n",
    "    point = [a.tolist() for i,a in enumerate(point) if count[i] >= 2]\n",
    "    \n",
    "    li_pos_COG2 = [i for i in li_pos_COG if i[0] in point and i[1] in point]\n",
    "    #drawline(outputImg, li_pos_COG2)\n",
    "    #print(li_pos_COG)\n",
    "    #drawline(outputImg, COG)\n",
    "    #print(li_list)\n",
    "    #print(point)\n",
    "    \n",
    "    #推測したサークルポイントを表示させる\n",
    "    drawline(outputImg, li_pos_COG2, color=(0, 255, 0), size= 3)\n",
    "    drawpoint(outputImg, COG)\n",
    "    drawpoint(outputImg, point, color=(0, 255, 0))\n",
    "    \n",
    "    #表示\n",
    "    return outputImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### カメラデバイスを使う(リアルタイム)\n",
    "def camera():\n",
    "    window_name = \"camera_et\"\n",
    "    cap = cv2.VideoCapture(2)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        sys.exit()\n",
    "    ret, frame = cap.read()\n",
    "    width = frame.shape[0]\n",
    "    height = frame.shape[1]\n",
    "    \n",
    "    while True:\n",
    "        #カメラからの画像取得\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        out_img = main(frame)\n",
    "        out_img = cv2.resize(out_img, (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))) #(int(width*2), int(height*2))\n",
    "        #カメラの画像の出力\n",
    "        cv2.imshow('camera' , out_img)\n",
    "\n",
    "        #繰り返し分から抜けるためのif文\n",
    "        key = cv2.waitKey(33)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    #メモリを解放して終了するためのコマンド\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 動画データを使う\n",
    "def video(file_name):\n",
    "    window_name = \"video_et\"\n",
    "    cap_file = cv2.VideoCapture(file_name)\n",
    "\n",
    "    if not cap_file.isOpened():\n",
    "        sys.exit()\n",
    "    ret, frame = cap_file.read()\n",
    "    width = frame.shape[0]\n",
    "    height = frame.shape[1]\n",
    "    \n",
    "\n",
    "    wait_time = int(round(cap_file.get(cv2.CAP_PROP_FPS), 0))\n",
    "    while True:\n",
    "        ret, frame = cap_file.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        out_img = main(frame)\n",
    "        out_img = cv2.resize(out_img, (int(cap_file.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap_file.get(cv2.CAP_PROP_FRAME_HEIGHT)))) #(int(width*1.2), int(height*1.2))\n",
    "        cv2.imshow(window_name, out_img)\n",
    "\n",
    "        key = cv2.waitKey(wait_time)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "    cap_file.release()\n",
    "    cv2.destroyWindow(window_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###画像データを使う\n",
    "def image(file_name):\n",
    "    img = cv2.imread(file_name)\n",
    "    out_img = main(img)\n",
    "    plt.imshow(np.asarray(out_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### execute #####\n",
    "\n",
    "#image(\"output.png\")\n",
    "video(\"video2.mp4\")\n",
    "#camera()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
